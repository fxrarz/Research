{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0RGdzr3v0x2H",
        "EJ4gHh8e9Zrk",
        "QAlHitn7PivD",
        "rt-qdsTY1WK8",
        "moJvDaPT1hBw",
        "ul38ml6pHIkR",
        "lslgXR-uHPlg",
        "08XMYyD-HTv6",
        "7eIOmuqEHYhp",
        "RPW0G-g38gjA",
        "inI1gSwQ8rgE",
        "4BKdoh5o8rgE",
        "NLiyTEit8rgE",
        "mpDFXlqF8rgE",
        "KjVkBdfG8rgE",
        "yI0Xjro98rgE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**TRAINING CLASSIFICATION MODEL**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Platform**: Colab\n",
        "\n",
        "**Requirement**: GPU\n",
        "\n",
        "**Written on**: 14 September 2021\n",
        "\n",
        "**Tested on**: 22 September 2021\n",
        "\n",
        "**Author**: A.S. Faraz Ahmed\n",
        "\n",
        "**Description**: \n",
        "\n",
        "> Train Classifier"
      ],
      "metadata": {
        "id": "DTjDDdxuov1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "0RGdzr3v0x2H"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fo6Ica81B_k"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "os.chdir('/content')\n",
        "if \"sample_data\" in os.listdir():\n",
        "  shutil.rmtree('sample_data/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaMuC0nW_kRU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c0a13ec-8c3e-40d7-df4a-508c2b2db935"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ4gHh8e9Zrk"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "WfgCnRmX1AAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier:\n",
        "  def __init__(self, data_dir, class_names, save_model):\n",
        "    self.data_dir = data_dir\n",
        "    self.class_names = class_names\n",
        "    self.save_model = save_model\n",
        "\n",
        "    self.image_size = (75, 75)\n",
        "    self.batch_size = 128\n",
        "    self.dataset_dir = \"/content/training/\"\n",
        "\n",
        "  def preprocesss(self):\n",
        "    self.train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "      pathlib.Path(self.dataset_dir),\n",
        "      validation_split=0.2,\n",
        "      subset=\"training\",\n",
        "      seed=1337,\n",
        "      image_size=self.image_size,\n",
        "      batch_size=self.batch_size,\n",
        "      shuffle=True,\n",
        "    )\n",
        "    self.val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "      pathlib.Path(self.dataset_dir),\n",
        "      validation_split=0.2,\n",
        "      subset=\"validation\",\n",
        "      seed=1337,\n",
        "      image_size=self.image_size,\n",
        "      batch_size=self.batch_size,\n",
        "      shuffle=True,\n",
        "    )\n",
        "    self.class_names = self.train_ds.class_names\n",
        "    print(\"Class Names: \",self.class_names)\n",
        "\n",
        "    self.num_classes = len(self.class_names)\n",
        "    print(\"Number of Classes: \",self.num_classes)\n",
        "\n",
        "  def visualize(self):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for images, labels in self.train_ds.take(1):\n",
        "      for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(self.class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "  def train(self):\n",
        "    IMG_RESIZE = 75\n",
        "    resize_and_rescale = tf.keras.Sequential([\n",
        "      layers.experimental.preprocessing.Resizing(IMG_RESIZE, IMG_RESIZE),\n",
        "      layers.experimental.preprocessing.Rescaling(1./255)\n",
        "    ])\n",
        "    self.model = Sequential([\n",
        "      resize_and_rescale,\n",
        "      layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "      layers.MaxPooling2D(),\n",
        "      layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "      layers.MaxPooling2D(),\n",
        "      layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "      layers.MaxPooling2D(),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dense(self.num_classes,activation='softmax')\n",
        "    ])\n",
        "    self.model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "    epochs=10\n",
        "    history = self.model.fit(\n",
        "      self.train_ds,\n",
        "      validation_data=self.val_ds,\n",
        "      epochs=epochs\n",
        "    )\n",
        "    self.model.summary()\n",
        "    self.model.save(self.save_model)\n",
        "\n",
        "  def evaluate(self, image, labels):\n",
        "    # image = mpimg.imread(image_path)\n",
        "    image = keras.preprocessing.image.load_img(\n",
        "        image, target_size=(self.image_size[0], self.image_size[1])\n",
        "    )\n",
        "    test_loss, test_acc = self.model.evaluate(image,  labels, verbose=2)\n",
        "    print(\"Test Loss: {}, Test Accuracy: {}\".format(test_loss, test_acc))\n",
        "\n",
        "  def test(self, image_path):\n",
        "    self.test_model = tf.keras.models.load_model(self.save_model)\n",
        "    img_height = 100\n",
        "    img_width = 100\n",
        "\n",
        "    img = mpimg.imread(image_path)\n",
        "    imgplot = plt.imshow(img)\n",
        "    plt.show()\n",
        "        \n",
        "    img = keras.preprocessing.image.load_img(\n",
        "        image_path, target_size=(self.image_size[0], self.image_size[1])\n",
        "    )\n",
        "    img_array = keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "    predictions = self.test_model.predict(img_array)\n",
        "    score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "    print(\n",
        "        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "        .format(self.class_names[np.argmax(score)], 100 * np.max(score))\n",
        "    )\n",
        "\n",
        "  def move_files(self):\n",
        "    os.system(\"mkdir /content/training/\")\n",
        "    for folder in self.class_names:\n",
        "      src = self.data_dir + \"/\" + folder\n",
        "      if os.path.exists(src):\n",
        "        des = \" /content/training/\"\n",
        "        os.system(\"cp -r \"+src+des)\n",
        "\n",
        "  def remove_files(self):\n",
        "    os.system(\"rm -r training/\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZzXsl5zY-c61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Raw Image"
      ],
      "metadata": {
        "id": "QAlHitn7PivD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShAjFkM6c7IU"
      },
      "source": [
        "%%bash\n",
        "cp \"/content/gdrive/MyDrive/dataset/Real Time Motion Control of a Humanoid Robot Using Deep Learnin/raw_with_test.tar.gz\" ./\n",
        "tar -xvzf raw_with_test.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in os.listdir(\"raw\"):\n",
        "  print(folder, \":\", len(os.listdir(\"raw/\"+folder)))"
      ],
      "metadata": {
        "id": "M43oGEsiJzHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e07c245f-c0a3-4377-debd-81dc579401af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rightup : 2400\n",
            "left : 2400\n",
            "up : 2400\n",
            "leftup : 2400\n",
            "right : 2400\n",
            "down : 2400\n",
            "full : 2400\n",
            "test : 690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "mv raw/test ./\n",
        "rm raw_with_test.tar.gz"
      ],
      "metadata": {
        "id": "jww8a7cTJ4lP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Class"
      ],
      "metadata": {
        "id": "rt-qdsTY1WK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "two_classes = Classifier(\"/content/raw\", [\"up\", \"down\"], \"raw_2.h5\")\n",
        "two_classes.move_files()\n",
        "two_classes.preprocesss()\n",
        "two_classes.visualize()\n",
        "two_classes.train()\n",
        "two_classes.evaluate(\"/content/test/100.jpg\", \"up\")\n",
        "two_classes.test(\"/content/test/100.jpg\") #up\n",
        "two_classes.test(\"/content/test/1.jpg\") #down\n",
        "two_classes.remove_files()"
      ],
      "metadata": {
        "id": "pFogRFrf1FtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ZIP FILES\n",
        "!tar -czvf raw_2class_with_test.tar.gz ./raw_2.h5 ./test/\n",
        "!rm -r /content/raw_2.h5"
      ],
      "metadata": {
        "id": "IxITExJJqFy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNZIP FILES\n",
        "!tar -xvzf raw_2class_with_test.tar.gz ./"
      ],
      "metadata": {
        "id": "t7PqgC5f71Su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Class"
      ],
      "metadata": {
        "id": "moJvDaPT1hBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "three_classes = Classifier(\"/content/raw\", [\"up\", \"down\", \"full\"], \"raw_3.h5\")\n",
        "three_classes.move_files()\n",
        "three_classes.preprocesss()\n",
        "three_classes.visualize()\n",
        "three_classes.train()\n",
        "three_classes.evaluate(\"/content/test/346.jpg\", \"full\")\n",
        "three_classes.test(\"/content/test/100.jpg\") #up\n",
        "three_classes.test(\"/content/test/5.jpg\") #down\n",
        "three_classes.test(\"/content/test/346.jpg\") #full\n",
        "three_classes.remove_files()"
      ],
      "metadata": {
        "id": "M0gP0k321Jyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ZIP FILES\n",
        "!tar -czvf raw_3class_with_test.tar.gz ./raw_3.h5 ./test/\n",
        "!rm -r /content/raw_3.h5"
      ],
      "metadata": {
        "id": "x6uPKbfU2oAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNZIP FILES\n",
        "!tar -xvzf raw_3class_with_test.tar.gz ./"
      ],
      "metadata": {
        "id": "UBwpfHPk7oJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Class"
      ],
      "metadata": {
        "id": "ul38ml6pHIkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "four_classes = Classifier(\"/content/raw\", [\"up\", \"down\", \"full\", \"right\"], \"raw_4.h5\")\n",
        "four_classes.move_files()\n",
        "four_classes.preprocesss()\n",
        "four_classes.visualize()\n",
        "four_classes.train()\n",
        "four_classes.evaluate(\"/content/test/346.jpg\", \"full\")\n",
        "four_classes.test(\"/content/test/381.jpg\") #up\n",
        "four_classes.test(\"/content/test/518.jpg\") #down\n",
        "four_classes.test(\"/content/test/346.jpg\") #full\n",
        "four_classes.test(\"/content/test/463.jpg\") #right\n",
        "four_classes.remove_files()"
      ],
      "metadata": {
        "id": "U_Ce5O2wHeIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ZIP FILES\n",
        "!tar -czvf raw_4class_with_test.tar.gz ./raw_4.h5 ./test/\n",
        "!rm -r /content/raw_4.h5"
      ],
      "metadata": {
        "id": "Crg-rqbbHkK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNZIP FILES\n",
        "!tar -xvzf raw_4class_with_test.tar.gz ./"
      ],
      "metadata": {
        "id": "6z0ejreD7j3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 Class"
      ],
      "metadata": {
        "id": "lslgXR-uHPlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "five_classes = Classifier(\"/content/raw\", [\"up\", \"down\", \"full\", \"right\", \"left\"], \"raw_5.h5\")\n",
        "five_classes.move_files()\n",
        "five_classes.preprocesss()\n",
        "five_classes.visualize()\n",
        "five_classes.train()\n",
        "five_classes.evaluate(\"/content/test/346.jpg\", \"full\")\n",
        "five_classes.test(\"/content/test/384.jpg\") #up\n",
        "five_classes.test(\"/content/test/5.jpg\") #down\n",
        "five_classes.test(\"/content/test/343.jpg\") #full\n",
        "five_classes.test(\"/content/test/501.jpg\") #right\n",
        "five_classes.test(\"/content/test/265.jpg\") #left\n",
        "five_classes.remove_files()"
      ],
      "metadata": {
        "id": "k50kUIAcNocC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ZIP FILES\n",
        "!tar -czvf raw_5class_with_test.tar.gz ./skeleton_5.h5 ./test/\n",
        "!rm -r /content/raw_5.h5"
      ],
      "metadata": {
        "id": "1FYss0aXNs4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNZIP FILES\n",
        "!tar -xvzf raw_5class_with_test.tar.gz ./"
      ],
      "metadata": {
        "id": "cHzjq5WsNuu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 Class"
      ],
      "metadata": {
        "id": "08XMYyD-HTv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "six_classes = Classifier(\"/content/raw\", [\"up\", \"down\", \"full\", \"right\", \"left\", \"rightup\"], \"raw_6.h5\")\n",
        "six_classes.move_files()\n",
        "six_classes.preprocesss()\n",
        "six_classes.visualize()\n",
        "six_classes.train()\n",
        "six_classes.evaluate(\"/content/test/346.jpg\", \"full\")\n",
        "six_classes.test(\"/content/test/384.jpg\") #up\n",
        "six_classes.test(\"/content/test/5.jpg\") #down\n",
        "six_classes.test(\"/content/test/343.jpg\") #full\n",
        "six_classes.test(\"/content/test/501.jpg\") #right\n",
        "six_classes.test(\"/content/test/265.jpg\") #left\n",
        "six_classes.test(\"/content/test/405.jpg\") #rightup\n",
        "six_classes.remove_files()"
      ],
      "metadata": {
        "id": "xaOPUQmOOC4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ZIP FILES\n",
        "!tar -czvf raw_6class_with_test.tar.gz ./raw_6.h5 ./test/\n",
        "!rm -r /content/raw_6.h5\n",
        "\n",
        "# UNZIP FILES\n",
        "!tar -xvzf raw_6class_with_test.tar.gz ./"
      ],
      "metadata": {
        "id": "ognN1-D2OYA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7 Class"
      ],
      "metadata": {
        "id": "7eIOmuqEHYhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seven_classes = Classifier(\"/content/raw\", [\"up\", \"down\", \"full\", \"right\", \"left\", \"rightup\", \"leftup\"], \"raw_7.h5\")\n",
        "seven_classes.move_files()\n",
        "seven_classes.preprocesss()\n",
        "seven_classes.visualize()\n",
        "seven_classes.train()\n",
        "seven_classes.evaluate(\"/content/test/346.jpg\", \"full\")\n",
        "seven_classes.test(\"/content/test/384.jpg\") #up\n",
        "seven_classes.test(\"/content/test/5.jpg\") #down\n",
        "seven_classes.test(\"/content/test/343.jpg\") #full\n",
        "seven_classes.test(\"/content/test/501.jpg\") #right\n",
        "seven_classes.test(\"/content/test/265.jpg\") #left\n",
        "seven_classes.test(\"/content/test/405.jpg\") #rightup\n",
        "seven_classes.test(\"/content/test/597.jpg\") #leftup\n",
        "seven_classes.remove_files()"
      ],
      "metadata": {
        "id": "tllQ8-QMO5r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ZIP FILES\n",
        "!tar -czvf raw_7class_with_test.tar.gz ./raw_7.h5 ./test/\n",
        "!rm -r /content/raw_7.h5\n",
        "\n",
        "# UNZIP FILES\n",
        "!tar -xvzf raw_7class_with_test.tar.gz ./"
      ],
      "metadata": {
        "id": "piT-IZl_PN86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NaWCxGtV8ZlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "265 555 561 630 641 left\n",
        "381 384 100 up\n",
        "394 405 rightup\n",
        "463 501 right\n",
        "577 582 597 leftup\n",
        "5 518 662 down\n",
        "346 343 full"
      ],
      "metadata": {
        "id": "r5s4pdaLIo3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pose Estimated"
      ],
      "metadata": {
        "id": "RPW0G-g38gjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cp \"/content/gdrive/MyDrive/dataset/Real Time Motion Control of a Humanoid Robot Using Deep Learnin/pose_estimate_with_test.tar.gz\" ./\n",
        "tar -xvzf pose_estimate_with_test.tar.gz"
      ],
      "metadata": {
        "id": "3ZzBQA_68oY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in os.listdir(\"raw\"):\n",
        "  print(folder, \":\", len(os.listdir(\"pose_estimate/\"+folder)))"
      ],
      "metadata": {
        "id": "wNcY-Aex9vsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "mv pose_estimate/test ./\n",
        "rm pose_estimate_with_test.tar.gz"
      ],
      "metadata": {
        "id": "EjsVdFMb9ze7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Class"
      ],
      "metadata": {
        "id": "inI1gSwQ8rgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "two_classes = Classifier(\"/content/pose_estimate\", [\"up\", \"down\"], \"skeleton_2.h5\")\n",
        "two_classes.move_files()\n",
        "two_classes.preprocesss()\n",
        "two_classes.visualize()\n",
        "two_classes.train()\n",
        "two_classes.evaluate(\"/content/test/100.jpg\", \"up\")\n",
        "two_classes.test(\"/content/test/100.jpg\") #up\n",
        "two_classes.test(\"/content/test/1.jpg\") #down\n",
        "two_classes.remove_files()"
      ],
      "metadata": {
        "id": "MOWtPIKp8rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ZIP FILES\n",
        "!tar -czvf pose_estimate_2class_with_test.tar.gz ./skeleton_2.h5 ./test/\n",
        "!rm -r /content/skeleton_2.h5"
      ],
      "metadata": {
        "id": "6OMmPOKc8rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNZIP FILES\n",
        "!tar -xvzf pose_estimate_2class_with_test.tar.gz ./"
      ],
      "metadata": {
        "id": "s884b6q08rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Class"
      ],
      "metadata": {
        "id": "4BKdoh5o8rgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "three_classes = Classifier(\"/content/pose_estimate\", [\"up\", \"down\", \"full\"], \"skeleton_3.h5\")\n",
        "three_classes.move_files()\n",
        "three_classes.preprocesss()\n",
        "three_classes.visualize()\n",
        "three_classes.train()\n",
        "three_classes.evaluate(\"/content/test/346.jpg\", \"full\")\n",
        "three_classes.test(\"/content/test/100.jpg\") #up\n",
        "three_classes.test(\"/content/test/5.jpg\") #down\n",
        "three_classes.test(\"/content/test/346.jpg\") #full\n",
        "three_classes.remove_files()"
      ],
      "metadata": {
        "id": "LnxOvJis8rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ZIP FILES\n",
        "!tar -czvf pose_estimate_3class_with_test.tar.gz ./skeleton_3.h5 ./test/\n",
        "!rm -r /content/skeleton_3.h5"
      ],
      "metadata": {
        "id": "tT6GU_zk8rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNZIP FILES\n",
        "!tar -xvzf pose_estimate_3class_with_test.tar.gz ./"
      ],
      "metadata": {
        "id": "8SU850Mq8rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Class"
      ],
      "metadata": {
        "id": "NLiyTEit8rgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "four_classes = Classifier(\"/content/pose_estimate\", [\"up\", \"down\", \"full\", \"right\"], \"skeleton_4.h5\")\n",
        "four_classes.move_files()\n",
        "four_classes.preprocesss()\n",
        "four_classes.visualize()\n",
        "four_classes.train()\n",
        "four_classes.evaluate(\"/content/test/346.jpg\", \"full\")\n",
        "four_classes.test(\"/content/test/381.jpg\") #up\n",
        "four_classes.test(\"/content/test/518.jpg\") #down\n",
        "four_classes.test(\"/content/test/346.jpg\") #full\n",
        "four_classes.test(\"/content/test/463.jpg\") #right\n",
        "four_classes.remove_files()"
      ],
      "metadata": {
        "id": "5qGy4hR78rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ZIP FILES\n",
        "!tar -czvf pose_estimate_4class_with_test.tar.gz ./skeleton_4.h5 ./test/\n",
        "!rm -r /content/skeleton_4.h5"
      ],
      "metadata": {
        "id": "87CKAY2d8rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNZIP FILES\n",
        "!tar -xvzf pose_estimate_4class_with_test.tar.gz ./"
      ],
      "metadata": {
        "id": "PTSLXBbU8rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 Class"
      ],
      "metadata": {
        "id": "mpDFXlqF8rgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "five_classes = Classifier(\"/content/pose_estimate\", [\"up\", \"down\", \"full\", \"right\", \"left\"], \"skeleton_5.h5\")\n",
        "five_classes.move_files()\n",
        "five_classes.preprocesss()\n",
        "five_classes.visualize()\n",
        "five_classes.train()\n",
        "five_classes.evaluate(\"/content/test/346.jpg\", \"full\")\n",
        "five_classes.test(\"/content/test/384.jpg\") #up\n",
        "five_classes.test(\"/content/test/5.jpg\") #down\n",
        "five_classes.test(\"/content/test/343.jpg\") #full\n",
        "five_classes.test(\"/content/test/501.jpg\") #right\n",
        "five_classes.test(\"/content/test/265.jpg\") #left\n",
        "five_classes.remove_files()"
      ],
      "metadata": {
        "id": "lkQsuWIb8rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ZIP FILES\n",
        "!tar -czvf pose_estimate_5class_with_test.tar.gz ./skeleton_5.h5 ./test/\n",
        "!rm -r /content/skeleton_5.h5"
      ],
      "metadata": {
        "id": "xKWnBZtI8rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNZIP FILES\n",
        "!tar -xvzf pose_estimate_5class_with_test.tar.gz ./"
      ],
      "metadata": {
        "id": "jbg6uSdm8rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 Class"
      ],
      "metadata": {
        "id": "KjVkBdfG8rgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "six_classes = Classifier(\"/content/pose_estimate\", [\"up\", \"down\", \"full\", \"right\", \"left\", \"rightup\"], \"skeleton_6.h5\")\n",
        "six_classes.move_files()\n",
        "six_classes.preprocesss()\n",
        "six_classes.visualize()\n",
        "six_classes.train()\n",
        "six_classes.evaluate(\"/content/test/346.jpg\", \"full\")\n",
        "six_classes.test(\"/content/test/384.jpg\") #up\n",
        "six_classes.test(\"/content/test/5.jpg\") #down\n",
        "six_classes.test(\"/content/test/343.jpg\") #full\n",
        "six_classes.test(\"/content/test/501.jpg\") #right\n",
        "six_classes.test(\"/content/test/265.jpg\") #left\n",
        "six_classes.test(\"/content/test/405.jpg\") #rightup\n",
        "six_classes.remove_files()"
      ],
      "metadata": {
        "id": "JjeoGKXM8rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ZIP FILES\n",
        "!tar -czvf pose_estimate_6class_with_test.tar.gz ./skeleton_6.h5 ./test/\n",
        "!rm -r /content/skeleton_6.h5\n",
        "\n",
        "# UNZIP FILES\n",
        "!tar -xvzf pose_estimate_6class_with_test.tar.gz ./"
      ],
      "metadata": {
        "id": "o3jiIVg-8rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7 Class"
      ],
      "metadata": {
        "id": "yI0Xjro98rgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seven_classes = Classifier(\"/content/pose_estimate\", [\"up\", \"down\", \"full\", \"right\", \"left\", \"rightup\", \"leftup\"], \"skeleton_7.h5\")\n",
        "seven_classes.move_files()\n",
        "seven_classes.preprocesss()\n",
        "seven_classes.visualize()\n",
        "seven_classes.train()\n",
        "seven_classes.evaluate(\"/content/test/346.jpg\", \"full\")\n",
        "seven_classes.test(\"/content/test/384.jpg\") #up\n",
        "seven_classes.test(\"/content/test/5.jpg\") #down\n",
        "seven_classes.test(\"/content/test/343.jpg\") #full\n",
        "seven_classes.test(\"/content/test/501.jpg\") #right\n",
        "seven_classes.test(\"/content/test/265.jpg\") #left\n",
        "seven_classes.test(\"/content/test/405.jpg\") #rightup\n",
        "seven_classes.test(\"/content/test/597.jpg\") #leftup\n",
        "seven_classes.remove_files()"
      ],
      "metadata": {
        "id": "vEAnMbQo8rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ZIP FILES\n",
        "!tar -czvf pose_estimate_7class_with_test.tar.gz ./skeleton_7.h5 ./test/\n",
        "!rm -r /content/skeleton_7.h5\n",
        "\n",
        "# UNZIP FILES\n",
        "!tar -xvzf pose_estimate_7class_with_test.tar.gz ./"
      ],
      "metadata": {
        "id": "MwMIZYmJ8rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Y41Vi7V8rgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "265 555 561 630 641 left\n",
        "381 384 100 up\n",
        "394 405 rightup\n",
        "463 501 right\n",
        "577 582 597 leftup\n",
        "5 518 662 down\n",
        "346 343 full"
      ],
      "metadata": {
        "id": "a3DGJFn08rgE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}