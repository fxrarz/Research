{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEZECLyKuVEY"
      },
      "source": [
        "**DATASET CREATION**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Platform**: Colab\n",
        "\n",
        "**Requirement**: GPU\n",
        "\n",
        "**Written on**: 14 September 2021\n",
        "\n",
        "**Tested on**: 22 September 2021\n",
        "\n",
        "**Author**: A.S. Faraz Ahmed\n",
        "\n",
        "**Description**: \n",
        "\n",
        "> Generates dataset for Pose classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzqetreaBfWI"
      },
      "source": [
        "# Record Video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOuoBcbnBvzQ"
      },
      "source": [
        "**1. Choose a Pose**\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://raw.githubusercontent.com/fxrarz/Research/main/Real_Time_Motion_Control_Of_A_Humanoid_Robot_Using_Deep_Learning/Asset/human-pose.jpg' height=\"350\" width=\"420\" />\n",
        "<figcaption>Arms Streched</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "**2. Record multiple video for that pose**\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://raw.githubusercontent.com/fxrarz/Research/main/Real_Time_Motion_Control_Of_A_Humanoid_Robot_Using_Deep_Learning/Asset/pose.gif' height=\"350\" width=\"420\" />\n",
        "</center>\n",
        "</figure>\n",
        "(Change background, dress, person, camera angle,  even video size settings)\n",
        "\n",
        "**3. Create a folder of pose name and paste the video**\n",
        "(Folder name is the class name)\n",
        "\n",
        "**4. Repeat Step 1 to 3 till all required pose are obtained**\n",
        "\n",
        "**5. Zip the folders using .tar extension**\n",
        "\n",
        "**5. Upload the zip file to Goodle Drive and remember the path**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFkAK69BXqqE"
      },
      "source": [
        "# Extract Image from Video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gKO8mYMmM5w"
      },
      "source": [
        "Remove existing file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2Th0l6lYr_U"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "os.chdir('/content')\n",
        "if \"sample_data\" in os.listdir():\n",
        "  shutil.rmtree('sample_data/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc8kbQQcmUTM"
      },
      "source": [
        "Mount Google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn3s6Obqa27g",
        "outputId": "5c7af6d5-0866-413b-cddb-b1e8a81fce44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmonLsyhmask"
      },
      "source": [
        "Copy files from Google drive to Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJAKFo5eZAZk"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "gdrive_location=\"/gdrive/MyDrive/dataset/Videos.tar.gz\"\n",
        "cp $gdrive_location '/content/'\n",
        "#Extract zip\n",
        "tar -xvzf \"Videos.tar.gz\"\n",
        "#Remove Zip\n",
        "rm Videos.tar.gz\n",
        "mv Videos temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9JuzfWLmzD8"
      },
      "source": [
        "Extract images from videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8U_Zxko2L54",
        "outputId": "de5905a9-6d58-44c4-f96e-fff14f660671"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "path = \"/content/temp\"\n",
        "print('Available folders are: \\n', os.listdir(path))\n",
        "\n",
        "for folder in os.listdir(path):\n",
        "  video_folder = os.path.join(path,folder)\n",
        "  save_folder = video_folder.replace(\"temp\",\"raw\")\n",
        "  os.makedirs(save_folder)\n",
        "  print(save_folder)\n",
        "\n",
        "  files = os.listdir(video_folder)\n",
        "  i = 0\n",
        "  for f in files:\n",
        "    f = os.path.join(video_folder,f)\n",
        "    \n",
        "    cap = cv2.VideoCapture(f)\n",
        "    print(\"Original Video File\",f)\n",
        "    print(\"Save Folder location\",save_folder)\n",
        "    \n",
        "    while 1:\n",
        "      i+=1\n",
        "      _,frame = cap.read()\n",
        "      print(_)\n",
        "      if  _:\n",
        "        name = save_folder + \"/\" + str(i) + \".jpg\"\n",
        "        print(name)\n",
        "        frame = cv2.rotate(frame,cv2.cv2.ROTATE_90_CLOCKWISE)\n",
        "        cv2.imwrite(name,frame)\n",
        "      else:\n",
        "        i-=1\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0mY4Rxr7DCY"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd /content/\n",
        "rm -r temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOAL575MH6mM"
      },
      "source": [
        "# Pose Estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pClJO864nJbM"
      },
      "source": [
        "COCO & TF Pose Estimation Models are Available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_xqPgdzIDwI"
      },
      "source": [
        "## Using COCO Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sqVsqR5nXV0"
      },
      "source": [
        "Change OpenCV Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayXVGTctIUQY"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python==4.3.0.38"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z8hFJHjnbik"
      },
      "source": [
        "Download COCO Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEmnOhFvIWxU"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "wget https://raw.githubusercontent.com/spmallick/learnopencv/master/OpenPose/getModels.sh\n",
        "sh getModels.sh\n",
        "cd pose/coco/\n",
        "wget https://raw.githubusercontent.com/spmallick/learnopencv/master/OpenPose/pose/coco/pose_deploy_linevec.prototxt\n",
        "cd ../../\n",
        "rm getModels.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opiqZ5KBnibM"
      },
      "source": [
        "Set GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0eC0kyGIbs8"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "protoFile = \"pose/coco/pose_deploy_linevec.prototxt\"\n",
        "weightsFile = \"pose/coco/pose_iter_440000.caffemodel\"\n",
        "nPoints = 18\n",
        "POSE_PAIRS = [ [1,0],[1,2],[1,5],[2,3],[3,4],[5,6],[6,7],[1,8],[8,9],[9,10],[1,11],[11,12],[12,13],[0,14],[0,15],[14,16],[15,17]]\n",
        "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
        "\n",
        "device = \"gpu\"\n",
        "if device == \"cpu\":\n",
        "    net.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)\n",
        "    print(\"Using CPU device\")\n",
        "elif device == \"gpu\":\n",
        "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
        "    print(\"Using GPU device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoc4k-P5np0o"
      },
      "source": [
        "Initalize Pose Estimation script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zr6SCS5CJFf8"
      },
      "outputs": [],
      "source": [
        "path = \"/content/raw\"\n",
        "root = os.listdir(path)\n",
        "print('Available folders are: \\n', os.listdir(path))\n",
        "for folder in root:\n",
        "  image_folder = os.path.join(path,folder)\n",
        "  print(image_folder)\n",
        "  save_folder = image_folder.replace(\"raw\",\"coco\")\n",
        "  os.makedirs(save_folder)\n",
        "  num = 0\n",
        "  while 1:\n",
        "    num += 1\n",
        "    image_file = image_folder + \"/\" + str(num) + \".jpg\"\n",
        "    print(image_file)\n",
        "    if os.path.isfile(image_file):\n",
        "      print(\"read path\",image_file)\n",
        "      savepath = image_file.replace(\"raw\",\"coco\")\n",
        "      print(\"save path\",savepath)      \n",
        "      frame = cv2.imread(image_file)\n",
        "      frameCopy = np.copy(frame)\n",
        "      frameWidth = frame.shape[1]\n",
        "      frameHeight = frame.shape[0]\n",
        "      threshold = 0.1\n",
        "      sketch = np.zeros((frameHeight,frameWidth,3), np.uint8)\n",
        "      inWidth = 368\n",
        "      inHeight = 368\n",
        "      inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight),(0, 0, 0), swapRB=False, crop=False)\n",
        "      net.setInput(inpBlob)\n",
        "      output = net.forward()\n",
        "      H = output.shape[2]\n",
        "      W = output.shape[3]\n",
        "      points = []\n",
        "      for i in range(nPoints):\n",
        "          # confidence map of corresponding body's part.\n",
        "          probMap = output[0, i, :, :]\n",
        "          # Find global maxima of the probMap.\n",
        "          minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
        "          # Scale the point to fit on the original image\n",
        "          x = (frameWidth * point[0]) / W\n",
        "          y = (frameHeight * point[1]) / H\n",
        "          if prob > threshold : \n",
        "              points.append((int(x), int(y)))\n",
        "          else :\n",
        "              points.append(None)\n",
        "      for pair in POSE_PAIRS:\n",
        "          partA = pair[0]\n",
        "          partB = pair[1]\n",
        "          if points[partA] and points[partB]:\n",
        "              cv2.line(sketch, points[partA], points[partB], (random.randint(100,255), random.randint(150,255), random.randint(0,255)), 10)\n",
        "      plt.imshow(sketch)\n",
        "      frame = sketch\n",
        "      row = []\n",
        "      indexs = []\n",
        "      for i in range(frame.shape[0]):\n",
        "          index = 0\n",
        "          for x in frame[i]:\n",
        "              if x[0] != 0 or x[1] != 0 or x[2] != 0:\n",
        "                  row.append(i)\n",
        "                  indexs.append(index)\n",
        "                  break\n",
        "              index+=1\n",
        "      sx = min(indexs)\n",
        "      sy = row[0]\n",
        "      row = []\n",
        "      indexs = []\n",
        "      for i in range(frame.shape[0]):\n",
        "          index = 0\n",
        "          for x in frame[i]:\n",
        "              if x[0] != 0 or x[1] != 0 or x[2] != 0:\n",
        "                  row.append(i)\n",
        "                  indexs.append(index)\n",
        "              index+=1\n",
        "      dx = max(indexs)\n",
        "      dy = row[-1]\n",
        "      try:\n",
        "          cropped_image = frame[sy:dy, sx:dx]\n",
        "          cv2.imwrite(savepath,cropped_image)\n",
        "          plt.imshow(cropped_image)\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "    else:\n",
        "      break\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7Tdb5ytP8fQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0b0wLb1UtZU"
      },
      "source": [
        "## Using TensorFLow Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjcnJbyooC64"
      },
      "source": [
        "Change OpenCV version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe9G10dvU2dA",
        "outputId": "6d7e36d2-4f09-4831-fe63-0636824e065a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q imageio\n",
        "!pip install -q opencv-python\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Jc-CeBIoRng"
      },
      "source": [
        "Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbKgZoC6U_80"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow_docs.vis import embed\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Import matplotlib libraries\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.collections import LineCollection\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Some modules to display an animation using imageio.\n",
        "import imageio\n",
        "from IPython.display import HTML, display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmfseoV4kl2M"
      },
      "source": [
        "Download Pose Estimation Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzpc1OFtkl2M"
      },
      "outputs": [],
      "source": [
        "KEYPOINT_DICT = {\n",
        "    'nose': 0,\n",
        "    'left_eye': 1,\n",
        "    'right_eye': 2,\n",
        "    'left_ear': 3,\n",
        "    'right_ear': 4,\n",
        "    'left_shoulder': 5,\n",
        "    'right_shoulder': 6,\n",
        "    'left_elbow': 7,\n",
        "    'right_elbow': 8,\n",
        "    'left_wrist': 9,\n",
        "    'right_wrist': 10,\n",
        "    'left_hip': 11,\n",
        "    'right_hip': 12,\n",
        "    'left_knee': 13,\n",
        "    'right_knee': 14,\n",
        "    'left_ankle': 15,\n",
        "    'right_ankle': 16\n",
        "}\n",
        "\n",
        "# Maps bones to a matplotlib color name.\n",
        "KEYPOINT_EDGE_INDS_TO_COLOR = {\n",
        "    (0, 1): 'm',\n",
        "    (0, 2): 'c',\n",
        "    (1, 3): 'm',\n",
        "    (2, 4): 'c',\n",
        "    (0, 5): 'm',\n",
        "    (0, 6): 'c',\n",
        "    (5, 7): 'm',\n",
        "    (7, 9): 'm',\n",
        "    (6, 8): 'c',\n",
        "    (8, 10): 'c',\n",
        "    (5, 6): 'y',\n",
        "    (5, 11): 'm',\n",
        "    (6, 12): 'c',\n",
        "    (11, 12): 'y',\n",
        "    (11, 13): 'm',\n",
        "    (13, 15): 'm',\n",
        "    (12, 14): 'c',\n",
        "    (14, 16): 'c'\n",
        "}\n",
        "\n",
        "if 'pose_model' in os.listdir('/content/'):\n",
        "  pose_estimation = tf.saved_model.load('pose_model')\n",
        "else:\n",
        "  import tensorflow_hub as hub\n",
        "  pose_estimation = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
        "\n",
        "input_size = 192\n",
        "# Create a object\n",
        "model = pose_estimation.signatures['serving_default']\n",
        "\n",
        "\n",
        "frameHeight = 1440 \n",
        "frameWidth = 1440\n",
        "sketch = np.zeros((frameHeight,frameWidth,3), np.uint8)\n",
        "cv2.imwrite(\"/content/bg.jpg\",sketch)\n",
        "\n",
        "bg_image = tf.io.read_file('/content/bg.jpg')\n",
        "bg_image = tf.image.decode_jpeg(bg_image)\n",
        "\n",
        "\n",
        "# Expand Dimensions\n",
        "display_image_with_black_bg = tf.expand_dims(bg_image, axis=0)\n",
        "# Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
        "display_image_with_black_bg = tf.cast(tf.image.resize_with_pad(display_image_with_black_bg, 1280, 1280), dtype=tf.int32)\n",
        "# Draw prediction on display_image_bg\n",
        "display_image_with_black_bg = np.squeeze(display_image_with_black_bg.numpy(), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AaichSvn3Jw"
      },
      "source": [
        "Initalize Pose Estimation script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmpjGyA1kl2M",
        "outputId": "db78ef6c-0739-4ee2-d774-d995b59edebb"
      },
      "outputs": [],
      "source": [
        "bg_image = tf.io.read_file('/content/bg.jpg')\n",
        "bg_image = tf.image.decode_jpeg(bg_image)\n",
        "input_image_bg = tf.expand_dims(bg_image, axis=0)\n",
        "input_image_bg = tf.image.resize_with_pad(input_image_bg, input_size, input_size)\n",
        "\n",
        "path = \"/content/raw\"\n",
        "root = os.listdir(path)\n",
        "print('Available folders are: \\n', os.listdir(path))\n",
        "for folder in root:\n",
        "  image_folder = os.path.join(path,folder)\n",
        "  print(image_folder)\n",
        "  save_folder = image_folder.replace(\"raw\",\"tf\")\n",
        "  os.makedirs(save_folder)\n",
        "  num = 0\n",
        "  while 1:\n",
        "    num += 1\n",
        "    image_file = image_folder + \"/\" + str(num) + \".jpg\"\n",
        "    print(image_file)\n",
        "    if os.path.isfile(image_file):\n",
        "      print(\"read path\",image_file)\n",
        "      savepath = image_file.replace(\"raw\",\"tf\")\n",
        "      print(\"save path\",savepath)      \n",
        "      \n",
        "      # Load the input image.\n",
        "        # Read as io\n",
        "      image = tf.io.read_file(image_file)\n",
        "        # Decode io\n",
        "      image = tf.image.decode_jpeg(image)\n",
        "        # Expand Dimensions\n",
        "      input_image = tf.expand_dims(image, axis=0)\n",
        "        # Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
        "      input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
        "\n",
        "      # Run model inference.\n",
        "        # SavedModel format expects tensor type of int32.\n",
        "      input_image = tf.cast(input_image, dtype=tf.int32)\n",
        "      # Run model inference.\n",
        "      outputs = model(input_image)\n",
        "      # Output is a [1, 1, 17, 3] tensor.\n",
        "      keypoints_with_scores = outputs['output_0'].numpy()\n",
        "\n",
        "      # Visualize the predictions with image_bg.\n",
        "      height, width, channel = display_image_with_black_bg.shape\n",
        "      aspect_ratio = float(width) / height\n",
        "      fig, ax = plt.subplots(figsize=(12 * aspect_ratio, 12))\n",
        "          # To remove the huge white borders\n",
        "      fig.tight_layout(pad=-2.50)\n",
        "          # fig.tight_layout(pad=0)\n",
        "      ax.margins(0)\n",
        "      ax.set_yticklabels([])\n",
        "      ax.set_xticklabels([])\n",
        "      plt.axis('off')\n",
        "      im = ax.imshow(display_image_with_black_bg)\n",
        "      line_segments = LineCollection([], linewidths=(10), linestyle='solid')\n",
        "      ax.add_collection(line_segments)\n",
        "          # Turn off tick labels\n",
        "      scat = ax.scatter([], [], s=60, color='#FF1493', zorder=3)\n",
        "\n",
        "      # _keypoints_and_edges_for_display\n",
        "      keypoint_threshold=0.11\n",
        "      keypoints_all = []\n",
        "      keypoint_edges_all = []\n",
        "      edge_colors = []\n",
        "      num_instances, _, _, _ = keypoints_with_scores.shape\n",
        "      for idx in range(num_instances):\n",
        "        kpts_x = keypoints_with_scores[0, idx, :, 1]\n",
        "        kpts_y = keypoints_with_scores[0, idx, :, 0]\n",
        "        kpts_scores = keypoints_with_scores[0, idx, :, 2]\n",
        "        kpts_absolute_xy = np.stack([width * np.array(kpts_x), height * np.array(kpts_y)], axis=-1)\n",
        "        kpts_above_thresh_absolute = kpts_absolute_xy[kpts_scores > keypoint_threshold, :]\n",
        "        keypoints_all.append(kpts_above_thresh_absolute)\n",
        "        for edge_pair, color in KEYPOINT_EDGE_INDS_TO_COLOR.items():\n",
        "          if (kpts_scores[edge_pair[0]] > keypoint_threshold and kpts_scores[edge_pair[1]] > keypoint_threshold):\n",
        "            x_start = kpts_absolute_xy[edge_pair[0], 0]\n",
        "            y_start = kpts_absolute_xy[edge_pair[0], 1]\n",
        "            x_end = kpts_absolute_xy[edge_pair[1], 0]\n",
        "            y_end = kpts_absolute_xy[edge_pair[1], 1]\n",
        "            line_seg = np.array([[x_start, y_start], [x_end, y_end]])\n",
        "            keypoint_edges_all.append(line_seg)\n",
        "            edge_colors.append(color)\n",
        "      if keypoints_all:\n",
        "        keypoint_locs = np.concatenate(keypoints_all, axis=0)\n",
        "      else:\n",
        "        keypoint_locs = np.zeros((0, 17, 2))\n",
        "      if keypoint_edges_all:\n",
        "        keypoint_edges = np.stack(keypoint_edges_all, axis=0)\n",
        "      else:\n",
        "        keypoint_edges = np.zeros((0, 2, 2))\n",
        "      line_segments.set_segments(keypoint_edges)\n",
        "      line_segments.set_color(edge_colors)\n",
        "      if keypoint_edges.shape[0]:\n",
        "        line_segments.set_segments(keypoint_edges)\n",
        "        line_segments.set_color(edge_colors)\n",
        "      if keypoint_locs.shape[0]:\n",
        "        scat.set_offsets(keypoint_locs)\n",
        "        \n",
        "      fig.canvas.draw()\n",
        "      image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
        "      output_overlay_on_bg = image_from_plot.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "      plt.close(fig)\n",
        "      frame = output_overlay_on_bg\n",
        "\n",
        "\n",
        "      row = []\n",
        "      indexs = []\n",
        "      for i in range(frame.shape[0]):\n",
        "          index = 0\n",
        "          for x in frame[i]:\n",
        "              if x[0] != 0 or x[1] != 0 or x[2] != 0:\n",
        "                  row.append(i)\n",
        "                  indexs.append(index)\n",
        "                  break\n",
        "              index+=1\n",
        "      sx = min(indexs)\n",
        "      sy = row[0]\n",
        "      row = []\n",
        "      indexs = []\n",
        "      for i in range(frame.shape[0]):\n",
        "          index = 0\n",
        "          for x in frame[i]:\n",
        "              if x[0] != 0 or x[1] != 0 or x[2] != 0:\n",
        "                  row.append(i)\n",
        "                  indexs.append(index)\n",
        "              index+=1\n",
        "      dx = max(indexs)\n",
        "      dy = row[-1]\n",
        "      try:\n",
        "          cropped_image = frame[sy:dy, sx:dx]\n",
        "          cv2.imwrite(savepath,cropped_image)\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "    else:\n",
        "      break\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNPHZSKqg7Fc"
      },
      "source": [
        "# Upload Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNU7LhkSkl2M"
      },
      "source": [
        "Upload dataset to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5SCBhPehCoQ"
      },
      "outputs": [],
      "source": [
        "!tar -zcvf /content/classification_dataset.tar.gz /content/raw content/coco /content/pose\n",
        "!mv /content/classification_dataset.tar.gz /gdrive/MyDrive/dataset/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Dataset Creation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
